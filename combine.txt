// ====================
// File: ./src/ui.rs
// ====================
// src/ui.rs
use crate::app::{App, FocusedPanel};
use ratatui::{
    Frame,
    backend::Backend,
    layout::{Constraint, Direction, Layout, Rect}, // Added Rect for inner areas if needed
    style::{Color, Modifier, Style},               // Added Modifier for more styling options
    widgets::{Block, Borders, List, ListItem, Paragraph, Wrap}, // Added Wrap for Paragraphs
};

/// Formats a given description string by either processing it as HTML, plain text,
/// or returning a default message if the description is `None`.
///
/// # Arguments
///
/// * `description` - An `Option<&str>` containing the description text.
///   - If `Some`, the string may contain plain text or HTML.
///   - If `None`, a default "No show notes available" message is returned.
///
/// # Returns
///
/// A `String` containing the formatted description:
/// - If the description appears to contain HTML tags (determined by a simple heuristic),
///   the function attempts to parse and extract plain text using the `html2text` crate.
///   - Successfully parsed text is further processed to:
///     - Trim trailing whitespace on each line.
///     - Remove any empty lines.
/// - If HTML parsing fails, the raw input string is returned as a fallback,
///   and an error is logged to `stderr`.
/// - If the description does not contain HTML or parsing is not required, the plain `&str`
///   is directly converted to a `String`.
/// - If `description` is `None`, a default string "No show notes available for this episode."
///   is returned.
pub fn format_description(description: Option<&str>) -> String {
    const DEFAULT_TEXT_WIDTH: usize = 80;
    match description {
        Some(desc_str) => {
            // A simple heuristic: if it looks like HTML, try to convert it.
            if desc_str.contains('<') && desc_str.contains('>') && desc_str.contains("</") {
                // Slightly better HTML check
                match html2text::from_read(desc_str.as_bytes(), DEFAULT_TEXT_WIDTH) {
                    // 80 is example width
                    Ok(text_content) => {
                        // Process the successfully converted text
                        text_content
                            .lines()
                            .map(|line| line.trim_end()) // Trim trailing whitespace
                            .filter(|line| !line.is_empty()) // Optional: remove empty lines
                            .collect::<Vec<&str>>() // Collect as Vec<&str> first
                            .join("\n")
                    }
                    Err(_e) => {
                        // If html2text fails, fallback to rendering the original string
                        // You might want to log the error _e here for debugging
                        eprintln!("Failed to parse HTML description with html2text: {}", _e);
                        desc_str.to_string() // Fallback
                    }
                }
            } else {
                // Assume it's plain text or Markdown that we're not yet processing richly
                desc_str.to_string()
            }
        }
        None => "No show notes available for this episode.".to_string(),
    }
    .trim()
    .to_string()
}

pub struct LayoutChunks {
    pub player_chunk: Rect,
    pub content_chunk: Rect,
    pub hint_chunk: Rect,
    pub podcasts_chunk: Rect,
    pub episodes_chunk: Rect,
    pub show_notes_chunk: Rect,
}

pub fn compute_layout(frame_size: Rect) -> LayoutChunks {
    let main_chunks = Layout::default()
        .direction(Direction::Vertical)
        .constraints([Constraint::Length(3), Constraint::Min(0), Constraint::Length(1)])
        .split(frame_size);

    let content_chunk = main_chunks[1];

    let content_columns = Layout::default()
        .direction(Direction::Horizontal)
        .constraints([
            Constraint::Percentage(33),
            Constraint::Percentage(33),
            Constraint::Percentage(34),
        ])
        .split(content_chunk);

    LayoutChunks {
        player_chunk: main_chunks[0],
        content_chunk,
        hint_chunk: main_chunks[2],
        podcasts_chunk: content_columns[0],
        episodes_chunk: content_columns[1],
        show_notes_chunk: content_columns[2],
    }
}

/// This function prepares layout (only for show_notes height right now)
/// and updates mutable state outside the draw closure.
pub fn prepare_ui_layout(app: &mut App, frame_size: Rect) {
    let layout_chunks = compute_layout(frame_size);

    let is_show_notes_focused = app.focused_panel == FocusedPanel::ShowNotes; // Need app state for focus style
    let focused_style = Style::default().fg(Color::Cyan); // Assuming these are accessible or defined
    let default_style = Style::default().fg(Color::White);

    // Temporarily construct the block to get its inner dimensions.
    // The title string here doesn't have to be the final dynamic one,
    // as long as it doesn't change the *height* of the title area.
    // If the title string can wrap and take multiple lines, this becomes more complex.
    // Assuming single-line titles for now for simplicity of inner calculation.
    let temp_show_notes_block = Block::default()
        .title("Show Notes Placeholder") // Placeholder or actual title logic
        .borders(Borders::ALL)
        .border_style(if is_show_notes_focused { focused_style } else { default_style });

    // 2. Calculate the inner area of this block IF IT WERE RENDERED in show_notes_chunk.
    let inner_area = temp_show_notes_block.inner(layout_chunks.show_notes_chunk);
    //
    // eprintln!("--- UI Frame ---");
    // eprintln!("Show Notes Chunk: {:?}", layout_chunks.show_notes_chunk);
    // eprintln!("Inner Area for Paragraph: {:?}", inner_area);
    // eprintln!("Set state dimensions to: width={}, height={}", inner_area.width, inner_area.height);
    // eprintln!("App Show Notes State - panel_w: {}, panel_h: {}", app.show_notes_state.panel_width, app.show_notes_state.panel_height);
    // eprintln!("App Show Notes State - content lines: {}", app.show_notes_state.content.lines().count());
    // eprintln!("App Show Notes State - max_scroll: {}", app.show_notes_state.max_scroll_vertical()); // Call internal directly for debug
    // eprintln!("App Show Notes State - current_scroll: {}", app.show_notes_state.scroll_offset_vertical);

    app.show_notes_state.set_dimensions(inner_area.width, inner_area.height);
}

pub fn ui<B: Backend>(f: &mut Frame, app: &App) {
    // === Layout Definitions ===

    let layout = compute_layout(f.size());

    let player_chunk = layout.player_chunk;
    // let content_chunk = layout.content_chunk;
    let hint_chunk = layout.hint_chunk;

    let podcasts_chunk = layout.podcasts_chunk;
    let episodes_chunk = layout.episodes_chunk;
    let show_notes_chunk = layout.show_notes_chunk;

    // === Define Styles ===
    let default_style = Style::default().fg(Color::White);
    let focused_style = Style::default().fg(Color::Cyan); // Or another distinct color like LightBlue
    let selected_item_style = Style::default().fg(Color::Yellow).add_modifier(Modifier::BOLD);
    let unfocused_selected_item_style = Style::default().fg(Color::LightCyan); // If you want to dim selection in unfocused lists

    let selected_podcast = app.selected_podcast();
    let selected_episode = app.selected_episode();

    // === Player Panel ===
    let (player_title, player_text) =
        if let Some((podcast_title, episode_title)) = &app.playing_episode {
            ("Now Playing".to_string(), format!("▶ {} - {}", podcast_title, episode_title))
        } else {
            ("Not Playing".to_string(), " ".to_string()) // Display a space or empty string
        };

    let player_widget = Paragraph::new(player_text)
        // .style(Style::default().fg(Color::LightGreen)) // Style for the text
        .wrap(Wrap { trim: true }) // Wrap text if it's too long
        .block(
            Block::default()
                .title(player_title)
                .borders(Borders::ALL)
                .style(Style::default().fg(Color::Green)), // Style for the block
        );
    f.render_widget(player_widget, player_chunk);

    // =============================================================================================
    // ================================== Podcasts Panel (Left) ===================================
    let is_podcasts_focused = app.focused_panel == FocusedPanel::Podcasts;
    let podcasts_block = Block::default() // Create the block styling separately
        .title("Podcasts")
        .borders(Borders::ALL)
        .border_style(if is_podcasts_focused { focused_style } else { default_style });

    let podcast_list_items: Vec<ListItem> = app
        .podcasts
        .iter()
        .enumerate()
        .map(|(i, podcast)| {
            let mut item = ListItem::new(podcast.title().to_string());
            if Some(i) == app.selected_podcast_index {
                if is_podcasts_focused {
                    item = item.style(selected_item_style); // Use the global Yellow Bold
                } else {
                    item = item.style(unfocused_selected_item_style); // Use the global DarkGray
                }
            } else {
                item = item.style(default_style); // Non-selected items
            }
            item
        })
        .collect();

    let podcasts_list_widget = List::new(podcast_list_items)
        .block(podcasts_block) // Pass the pre-styled block
        .highlight_symbol(if is_podcasts_focused { ">> " } else { "   " }); // Keep this conditional

    f.render_widget(podcasts_list_widget, podcasts_chunk);

    // =============================================================================================
    // ============================== Episodes Panel (Middle) ======================================
    let is_episode_focused = app.focused_panel == FocusedPanel::Episodes;

    // 1. Prepare List Items or Placeholder Message for Episodes
    let episode_list_items: Vec<ListItem> = match selected_podcast {
        Some(selected_podcast) => {
            if selected_podcast.episodes().is_empty() {
                vec![ListItem::new("No episodes for this podcast").style(default_style)]
            } else {
                selected_podcast
                    .episodes()
                    .iter()
                    .enumerate()
                    .map(|(i, episode)| {
                        let mut item = ListItem::new(episode.title().to_string());
                        if Some(i) == app.selected_episode_index {
                            item = item.style(if is_episode_focused {
                                selected_item_style
                            } else {
                                unfocused_selected_item_style
                            });
                        } else {
                            item = item.style(default_style); // Non-selected items
                        }
                        item
                    })
                    .collect()
            }
        }
        None => {
            vec![ListItem::new("Select a podcast to see episodes").style(default_style)]
        }
    };

    // 2. Prepare the Block for the Episodes Panel
    let episode_panel_title = selected_podcast.map_or_else(
        || "Episodes".to_string(), // Default title if no podcast selected
        |p| format!("Episodes for '{}'", p.title()), // Title with podcast name
    );

    let episodes_block = Block::default()
        .title(episode_panel_title) // Use the determined title
        .borders(Borders::ALL)
        .border_style(if is_episode_focused { focused_style } else { default_style });

    // 3. Construct the List Widget
    let episodes_list_widget = List::new(episode_list_items)
        .block(episodes_block)
        .highlight_symbol(if is_episode_focused { ">> " } else { "   " });
    // .highlight_style(selected_item_style) // Still optional/conditional based on ListState usage

    f.render_widget(episodes_list_widget, episodes_chunk);

    // =============================================================================================
    // ============================== Show Notes Panel (Right) =====================================
    let is_show_notes_focused = app.focused_panel == FocusedPanel::ShowNotes;

    // 1. Prepare Show Notes Text Content
    let show_notes_text_content = app.show_notes_state.content.clone();

    // 2. Prepare the Dynamic Panel Title
    let show_notes_panel_title_string: String = match selected_podcast {
        Some(podcast) => {
            match selected_episode {
                Some(episode) => {
                    // Both podcast and episode are selected
                    format!("Show Notes: {} - {}", podcast.title(), episode.title())
                }
                None => {
                    // Only podcast is selected, no specific episode yet
                    format!("Show Notes for '{}' (Select an episode)", podcast.title())
                }
            }
        }
        None => {
            // No podcast selected
            "Show Notes".to_string()
        }
    };

    // 3. Prepare the Block for the Show Notes Panel
    let show_notes_block = Block::default()
        .title(show_notes_panel_title_string) // Use the dynamically created title string
        .borders(Borders::ALL)
        .border_style(if is_show_notes_focused { focused_style } else { default_style });

    // 4. Construct the Paragraph Widget
    let show_notes_widget = Paragraph::new(show_notes_text_content)
        .wrap(Wrap { trim: true })
        .style(default_style) // Assuming default_style for the text
        .block(show_notes_block)
        .scroll((app.show_notes_state.scroll_offset_vertical, 0));

    // 5. Render
    f.render_widget(show_notes_widget, show_notes_chunk);

    // =============================================================================================
    // =============================== Hint Bar Panel (Bottom) =====================================

    // === Hint Bar / Status Bar (Bottom) ===
    let hint_text = "[←/→/Tab] Switch Panel | [↑/↓] Navigate List | [Space] Play/Pause | [Q] Quit";
    // You can make this dynamic later if keybindings change based on context

    let hint_widget = Paragraph::new(hint_text)
        .style(Style::default().fg(Color::DarkGray)) // Subtle color for hints
        .alignment(ratatui::layout::Alignment::Center); // Optional: center the text

    // If you want borders around the hint bar (Constraint::Length(3) for main_chunks[2] then):
    // let hint_widget = Paragraph::new(hint_text)
    //     .style(Style::default().fg(Color::DarkGray))
    //     .alignment(ratatui::layout::Alignment::Center)
    //     .block(Block::default().borders(Borders::TOP)); // Only top border

    f.render_widget(hint_widget, hint_chunk);
}

// ====================
// File: ./src/lib.rs
// ====================
// src/lib.rs
pub mod app;
mod errors;
pub mod podcast;
pub mod podcast_download;
pub mod podcast_factory;
pub mod ui;

pub mod commands;
pub mod event;
pub mod opml;
pub mod widgets;

// ====================
// File: ./src/podcast.rs
// ====================
// src/podcast.rs
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::fmt;

// === PODCAST STRUCTURES ===
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PodcastURL(String);

impl std::fmt::Display for PodcastURL {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.0)
    }
}

impl PartialEq for PodcastURL {
    fn eq(&self, other: &Self) -> bool {
        // Normalize URLs by trimming trailing slashes
        let a = self.0.trim_end_matches('/');
        let b = other.0.trim_end_matches('/');
        a == b
    }
}

impl Eq for PodcastURL {}

impl PodcastURL {
    pub fn new(s: &str) -> Self {
        PodcastURL(s.to_string())
    }

    pub fn as_str(&self) -> &str {
        self.0.as_str()
    }
}

impl AsRef<str> for PodcastURL {
    // Useful for passing to functions expecting &str
    fn as_ref(&self) -> &str {
        &self.0
    }
}

// === EPISODE STRUCTURES ===
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct EpisodeID(String);

impl std::fmt::Display for EpisodeID {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.0)
    }
}

impl EpisodeID {
    pub fn new(s: &str) -> Self {
        EpisodeID(s.to_string())
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Podcast {
    #[serde(rename = "url")]
    url: PodcastURL,
    #[serde(rename = "title")]
    title: String,
    #[serde(rename = "description")]
    description: Option<String>,
    #[serde(rename = "image_url")]
    image_url: Option<String>,
    #[serde(rename = "website_url")]
    website_url: Option<String>,
    #[serde(rename = "episodes")]
    episodes: Vec<Episode>,
    #[serde(rename = "last_updated")]
    last_updated: DateTime<Utc>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Episode {
    #[serde(rename = "id")]
    id: EpisodeID,
    #[serde(rename = "title")]
    title: String,
    #[serde(rename = "description")]
    description: Option<String>,
    #[serde(rename = "published_date")]
    published_date: DateTime<Utc>,
    #[serde(rename = "duration")]
    duration: Option<String>,
    #[serde(rename = "audio_url")]
    audio_url: String,
    #[serde(rename = "size_in_bytes")]
    size_in_bytes: Option<u64>,
}

impl Podcast {
    pub fn new(
        url: PodcastURL,
        title: String,
        description: Option<String>,
        image_url: Option<String>,
        website_url: Option<String>,
        episodes: Vec<Episode>,
    ) -> Self {
        Self { url, title, description, image_url, website_url, episodes, last_updated: Utc::now() }
    }
    // Accessor methods

    pub fn url(&self) -> &PodcastURL {
        &self.url
    }

    pub fn title(&self) -> &str {
        &self.title
    }

    pub fn description(&self) -> Option<&str> {
        self.description.as_deref()
    }

    pub fn image_url(&self) -> Option<&str> {
        self.image_url.as_deref()
    }

    pub fn website_url(&self) -> Option<&str> {
        self.website_url.as_deref()
    }

    pub fn episodes(&self) -> &[Episode] {
        &self.episodes
    }

    pub fn last_updated(&self) -> DateTime<Utc> {
        self.last_updated
    }

    // Mutable accessor for adding episodes
    pub fn add_episode(&mut self, episode: Episode) {
        self.episodes.push(episode);
    }
}

impl Episode {
    pub fn new(
        id: EpisodeID,
        title: String,
        description: Option<String>,
        published_date: DateTime<Utc>,
        duration: Option<String>,
        audio_url: String,
        size_in_bytes: Option<u64>,
    ) -> Self {
        Self { id, title, description, published_date, duration, audio_url, size_in_bytes }
    }

    pub fn id(&self) -> &EpisodeID {
        &self.id
    }

    pub fn title(&self) -> &str {
        &self.title
    }

    pub fn description(&self) -> Option<&str> {
        self.description.as_deref()
    }

    pub fn published_date(&self) -> DateTime<Utc> {
        self.published_date
    }

    pub fn duration(&self) -> Option<&str> {
        self.duration.as_deref()
    }

    pub fn audio_url(&self) -> &str {
        &self.audio_url
    }

    pub fn size_in_bytes(&self) -> Option<u64> {
        self.size_in_bytes
    }
}

impl fmt::Display for Podcast {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        writeln!(f, "Title       : {}", self.title)?;
        writeln!(f, "URL         : {}", self.url)?;
        if let Some(desc) = &self.description {
            writeln!(f, "Description : {}", desc)?;
        }
        if let Some(img) = &self.image_url {
            writeln!(f, "Image URL   : {}", img)?;
        }
        if let Some(web) = &self.website_url {
            writeln!(f, "Website URL : {}", web)?;
        }
        writeln!(f, "Episodes    : {}", self.episodes.len())?;
        writeln!(f, "Last updated: {}", self.last_updated)
    }
}

// ====================
// File: ./src/event.rs
// ====================
// src/event.rs
use crate::podcast::{Podcast};
use chrono::{DateTime, Utc};

#[derive(Debug, Clone)]
pub enum AppEvent {
    /// Emitted when a single podcast is fully processed (downloaded, parsed from an OPML entry)
    /// and is ready to be added to the application's main list.
    PodcastReadyForApp {
        podcast: Podcast,
        timestamp: DateTime<Utc>,
    },
}

// ====================
// File: ./src/opml/mod.rs
// ====================
// src/opml/mod.rs
pub mod opml_parser;

// ====================
// File: ./src/opml/opml_parser.rs
// ====================
// src/opml/opml_parser.rs
use opml::{OPML, Outline};
use std::fs;
use std::path::Path;
use thiserror::Error;

#[derive(Error, Debug)]
pub enum OpmlParseError {
    #[error("Failed to read OPML file: {0}")]
    FileReadError(#[from] std::io::Error),

    #[error("Failed to parse OPML data: {0}")]
    OpmlFormatError(#[from] opml::Error), // opml::Error from the opml crate

    #[error("OPML document has no body")]
    NoBody,

    #[error("Outline item is missing required 'xmlUrl' attribute for a feed")]
    MissingXmlUrl,

    #[error("Outline item is missing 'text' or 'title' attribute")]
    MissingTitle,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub struct OpmlFeedEntry {
    pub title: String,
    pub xml_url: String, // This is typically the feed URL
    pub html_url: Option<String>,
    // You can add other attributes like `text`, `description` if needed
}

/// Parses OPML content directly from a string.
///
/// It specifically looks for outlines of type "rss" or where an xmlUrl is present,
/// which usually represent podcast feeds.
///
/// # Arguments
/// * `opml_content` - A string slice containing the OPML XML data.
///
/// # Returns
/// A `Result` containing a `Vec<OpmlFeedEntry>` on success,
/// or an `OpmlParseError` on failure.
/// <?xml version="1.0" encoding="ASCII"?>
/// <opml version="2.0">
///     <head>
///         <title>castero feeds</title>
///     </head>
///     <body>
///         <outline type="rss" text="99% Invisible" xmlUrl="https://feeds.simplecast.com/BqbsxVfO"/>
///         <outline type="rss" text="Algorithms + Data Structures = Programs"

pub fn parse_opml_from_string(opml_content: &str) -> Result<Vec<OpmlFeedEntry>, OpmlParseError> {
    let document = OPML::from_str(opml_content)?;
    let mut feed_entries = Vec::new();

    // `document.body` is directly `opml::Body`
    // `document.body.outlines` is `Vec<opml::Outline>`
    for outline in document.body.outlines {
        // No if let Some needed
        process_outline_recursive(outline, &mut feed_entries)?;
    }
    // The case of a missing <body> tag would have caused OPML::from_str to fail.
    // An empty body (<body/>) would result in an empty document.body.outlines Vec.
    Ok(feed_entries)
}

/// Reads an OPML file from the given path and parses its content.
///
/// # Arguments
/// * `file_path` - A reference to a Path representing the location of the OPML file.
///
/// # Returns
/// A `Result` containing a `Vec<OpmlFeedEntry>` on success,
/// or an `OpmlParseError` on failure.
pub fn parse_opml_from_file<P: AsRef<Path>>(
    file_path: P,
) -> Result<Vec<OpmlFeedEntry>, OpmlParseError> {
    let opml_content = fs::read_to_string(file_path)?; // Propagates io::Error as OpmlParseError::FileReadError
    parse_opml_from_string(&opml_content)
}

// Helper function to recursively process outlines, as OPML can have nested groups.
fn process_outline_recursive(
    outline: Outline,
    feed_entries: &mut Vec<OpmlFeedEntry>,
) -> Result<(), OpmlParseError> {
    // Check if this outline represents a feed
    // Common indicators: type="rss" or the presence of an xml_url attribute.
    // Some OPMLs might not explicitly use type="rss" but will have xml_url for feeds.
    let is_feed = outline.r#type.as_deref().map_or(false, |t| t.eq_ignore_ascii_case("rss"))
        || outline.xml_url.is_some();

    if is_feed {
        // Assuming is_feed is determined correctly
        let final_title: String;

        if let Some(title_attr_val) = outline.title {
            // title_attr_val is String
            if !title_attr_val.is_empty() {
                final_title = title_attr_val; // Use title attribute if Some and not empty
            } else if !outline.text.is_empty() {
                // title attribute was Some(""), but text attribute has content
                final_title = outline.text; // Use text attribute
            } else {
                // title attribute was Some(""), and text attribute was also empty
                return Err(OpmlParseError::MissingTitle);
            }
        } else {
            // title attribute was None
            if !outline.text.is_empty() {
                final_title = outline.text; // Fallback to text attribute
            } else {
                // title attribute was None, and text attribute was also empty
                return Err(OpmlParseError::MissingTitle);
            }
        }
        // At this point, final_title is a non-empty String.

        let xml_url_str = outline
            .xml_url
            .filter(|s| !s.is_empty()) // Ensure it's not Some("")
            .ok_or(OpmlParseError::MissingXmlUrl)?;
        // xml_url_str is now a non-empty String.

        feed_entries.push(OpmlFeedEntry {
            title: final_title,
            xml_url: xml_url_str,
            html_url: outline.html_url, // This is Option<String>, which is fine if OpmlFeedEntry.html_url is Option<String>
        });
    }

    // Recursively process any child outlines (e.g., items within a folder)
    for child_outline in outline.outlines {
        process_outline_recursive(child_outline, feed_entries)?;
    }

    Ok(())
}

// Example Usage (you can put this in main.rs or tests)
#[cfg(test)]
mod tests {
    use super::*;

    const SAMPLE_OPML_V1: &str = r#"<?xml version="1.0" encoding="ISO-8859-1"?>
    <opml version="1.0">
        <head>
            <title>My Podcasts</title>
        </head>
        <body>
            <outline text="Tech Podcasts" title="Tech Podcasts">
                <outline text="Syntax FM" title="Syntax FM" type="rss" xmlUrl="http://feed.syntax.fm/rss" htmlUrl="https://syntax.fm"/>
                <outline title="Darknet Diaries" type="rss" xmlUrl="https://feeds.darknetdiaries.com/darknet-diaries.libsyn.com/rss" />
            </outline>
            <outline text="News" title="News Podcast (no type, but has xmlUrl)" xmlUrl="http://example.com/news.xml" />
        </body>
    </opml>"#;

    const SAMPLE_OPML_V2: &str = r#"<?xml version="1.0" encoding="UTF-8"?>
    <opml version="2.0">
        <head>
            <title>Subscriptions</title>
        </head>
        <body>
            <outline title="Rust Feeds">
                <outline title="This Week in Rust" text="This Week in Rust" type="rss" xmlUrl="https://this-week-in-rust.org/rss.xml" description="A weekly newsletter about Rust"/>
            </outline>
            <outline title="A Blog" xmlUrl="http://someblog.com/feed" /> 
        </body>
    </opml>"#;

    #[test]
    fn test_parse_from_string_v1() {
        let feeds = parse_opml_from_string(SAMPLE_OPML_V1).unwrap();
        assert_eq!(feeds.len(), 3);
        assert_eq!(feeds[0].title, "Syntax FM");
        assert_eq!(feeds[0].xml_url, "http://feed.syntax.fm/rss");
        assert_eq!(feeds[1].title, "Darknet Diaries");
        assert_eq!(feeds[2].title, "News Podcast (no type, but has xmlUrl)");
        assert_eq!(feeds[2].xml_url, "http://example.com/news.xml");
    }

    #[test]
    fn test_parse_from_string_v2() {
        let feeds = parse_opml_from_string(SAMPLE_OPML_V2).unwrap();
        assert_eq!(feeds.len(), 2);
        assert_eq!(feeds[0].title, "This Week in Rust");
        assert_eq!(feeds[0].xml_url, "https://this-week-in-rust.org/rss.xml");
        assert_eq!(feeds[1].title, "A Blog"); // Title is mandatory for our OpmlFeedEntry
        assert_eq!(feeds[1].xml_url, "http://someblog.com/feed");
    }

    #[test]
    fn test_missing_xml_url_is_skipped_unless_nested_valid() {
        let opml_missing_xml_url = r#"<?xml version="1.0" encoding="UTF-8"?>
        <opml version="1.0">
            <head><title>Test</title></head>
            <body>
                <outline text="No XML URL here" type="rss">
                    <outline text="Nested Feed" title="Nested Feed" type="rss" xmlUrl="http://example.com/nested.xml" />
                </outline>
            </body>
        </opml>"#;
        // The current logic for `is_feed` checks `outline.xml_url.is_some()`.
        // If the outer outline has type="rss" but no xmlUrl, it would try to create an OpmlFeedEntry.
        // The `xml_url.ok_or(OpmlParseError::MissingXmlUrl)?` would then cause an error.
        // This is correct: if it's marked as a feed, it should have an xmlUrl.
        // If the intent is to only extract items that are *definitely* feeds with all required info,
        // then an error is appropriate if a type="rss" outline is missing xmlUrl.
        // If the intent is to skip malformed feed entries, the `?` in process_outline_recursive needs to be handled
        // such that it doesn't stop processing siblings or other parts of the tree.
        // For now, let's test that it errors if a feed entry is malformed.

        // To test skipping, we'd need to make `process_outline_recursive` return Result<(), OpmlParseError>
        // and handle its error inside the loop, or filter more strictly before pushing.
        // Current `process_outline_recursive` uses `?` which propagates.

        let result = parse_opml_from_string(opml_missing_xml_url);
        // The outer outline will fail because it's type="rss" but has no xmlUrl.
        // The question is if the error from the outer outline prevents the inner one from being processed.
        // With the current `?` in the loop, an error in a child will propagate up and stop.
        // This behavior might be okay - if an OPML is malformed, maybe we stop.

        // Let's modify test for the current behavior: outer outline will fail.
        // The `title` for the outer outline is "No XML URL here".
        // It has `type="rss"`. `xml_url` is None.
        // This will trigger `OpmlParseError::MissingXmlUrl`.
        let opml_malformed_feed_entry = r#"<?xml version="1.0" encoding="UTF-8"?>
        <opml version="1.0">
            <head><title>Test</title></head>
            <body>
                <outline text="Malformed Feed" title="Malformed Feed" type="rss" htmlUrl="http://example.com" />
            </body>
        </opml>"#;
        let result_malformed = parse_opml_from_string(opml_malformed_feed_entry);
        assert!(matches!(result_malformed, Err(OpmlParseError::MissingXmlUrl)));

        // Test that even if an outer folder doesn't have feed attributes, inner ones are found
        let opml_folder_no_type = r#"<?xml version="1.0" encoding="UTF-8"?>
        <opml version="1.0">
            <head><title>Test</title></head>
            <body>
                <outline text="Just a Folder">
                    <outline text="Feed In Folder" title="Feed In Folder" type="rss" xmlUrl="http://example.com/feed_in_folder.xml" />
                </outline>
            </body>
        </opml>"#;
        let feeds = parse_opml_from_string(opml_folder_no_type).unwrap();
        assert_eq!(feeds.len(), 1);
        assert_eq!(feeds[0].title, "Feed In Folder");
    }

    // You would need an actual OPML file for this test to run, e.g., "test_data/sample.opml"
    // #[test]
    // fn test_parse_from_file() {
    //     // Create a dummy OPML file for testing
    //     let dir = tempfile::tempdir().unwrap();
    //     let file_path = dir.path().join("sample.opml");
    //     fs::write(&file_path, SAMPLE_OPML_V1).unwrap();
    //
    //     let feeds = parse_opml_from_file(file_path).unwrap();
    //     assert_eq!(feeds.len(), 3);
    //     assert_eq!(feeds[0].title, "Syntax FM");
    // }
}

// ====================
// File: ./src/podcast_download.rs
// ====================
// src/podcast_download.rs
use crate::errors::DownloaderError;
use crate::podcast::{Podcast, PodcastURL};
use crate::podcast_factory::{ParsedFeed, PodcastFactory};
use anyhow::Result;
use async_trait::async_trait;
use chrono::{DateTime, Utc};
use std::collections::HashMap;

#[derive(Debug, Clone)]
pub struct RawFeedData {
    pub content: String,
    pub fetch_date: DateTime<Utc>,
}

impl RawFeedData {
    pub fn from_string(content: String) -> Self {
        Self { content, fetch_date: Utc::now() }
    }
}

// ===== fetcher
#[async_trait]
pub trait FeedFetcher: Send + Sync {
    async fn fetch(&self, url: &str) -> Result<String, DownloaderError>;

    // New method for HEAD request
    async fn fetch_headers(&self, url: &str) -> Result<HashMap<String, String>, DownloaderError>;

    // New method for partial content
    async fn fetch_partial_content(
        &self,
        url: &str,
        byte_range: (u64, u64), // e.g., (0, 4095)
    ) -> Result<String, DownloaderError>;
}

// ===== Live http fetcher
pub struct HttpFeedFetcher {
    client: reqwest::Client,
}

impl HttpFeedFetcher {
    pub fn new() -> Self {
        Self { client: reqwest::Client::new() }
    }
}

#[async_trait]
impl FeedFetcher for HttpFeedFetcher {
    async fn fetch(&self, url: &str) -> Result<String, DownloaderError> {
        println!("HttpFeedFetcher: fetching {}", url);
        Ok(self
            .client
            .get(url)
            .send()
            .await
            .map_err(DownloaderError::NetworkError)?
            .text()
            .await
            .map_err(DownloaderError::NetworkError)?)
    }

    async fn fetch_headers(&self, url: &str) -> Result<HashMap<String, String>, DownloaderError> {
        let response = self.client.head(url).send().await.map_err(DownloaderError::NetworkError)?;
        if !response.status().is_success() {
            return Err(DownloaderError::Failed(format!(
                "HEAD request failed with status: {}",
                response.status()
            )));
        }
        let mut headers_map = HashMap::new();
        for (key, value) in response.headers().iter() {
            if let Ok(value_str) = value.to_str() {
                headers_map.insert(key.as_str().to_lowercase(), value_str.to_string());
            }
        }
        Ok(headers_map)
    }

    async fn fetch_partial_content(
        &self,
        url: &str,
        byte_range: (u64, u64),
    ) -> Result<String, DownloaderError> {
        let response = self
            .client
            .get(url)
            .header("Range", format!("bytes={}-{}", byte_range.0, byte_range.1))
            .send()
            .await
            .map_err(DownloaderError::NetworkError)?;

        if !response.status().is_success()
            && response.status() != reqwest::StatusCode::PARTIAL_CONTENT
        {
            return Err(DownloaderError::Failed(format!(
                "Partial GET request failed with status: {}",
                response.status()
            )));
        }
        response.text().await.map_err(DownloaderError::NetworkError)
    }
}

// ===== Fake http fetcher for testing
pub struct FakeFetcher {
    pub response: String,
}

#[async_trait]
impl FeedFetcher for FakeFetcher {
    async fn fetch(&self, _url: &str) -> Result<String, DownloaderError> {
        Ok(self.response.clone())
    }

    // New method for HEAD request

    async fn fetch_headers(&self, _url: &str) -> Result<HashMap<String, String>, DownloaderError> {
        // Return some fake headers, e.g., based on self.response for testing
        let mut headers = HashMap::new();
        if self.response.contains("<rss") || self.response.contains("<feed") {
            headers.insert("content-type".to_string(), "application/xml".to_string());
        } else {
            headers.insert("content-type".to_string(), "text/html".to_string());
        }
        Ok(headers)
    }

    // For partial content
    async fn fetch_partial_content(
        &self,
        _url: &str,
        byte_range: (u64, u64),
    ) -> Result<String, DownloaderError> {
        let start = byte_range.0 as usize;
        let end = (byte_range.1 + 1) as usize; // Range is inclusive, slice is exclusive at end
        if start < self.response.len() {
            let effective_end = std::cmp::min(end, self.response.len());
            Ok(self.response[start..effective_end].to_string())
        } else {
            Ok("".to_string())
        }
    }
}

// Implementation of the download function
pub async fn download_and_create_podcast(
    url: &PodcastURL,
    fetcher: &(dyn FeedFetcher + Send + Sync),
) -> Result<Podcast, DownloaderError> {
    println!("download_and_create_podcast: Fetching content for URL: {}", url.as_str());
    let content = fetcher.fetch(url.as_str()).await?;
    println!("download_and_create_podcast: Content fetched, length: {}", content.len());
    let channel = rss::Channel::read_from(content.as_bytes())?;
    let parsed = ParsedFeed { channel };

    PodcastFactory::new().create_podcast(parsed, url.to_string())
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::podcast::PodcastURL;

    #[tokio::test]
    async fn test_download_and_create_podcast() {
        // Create a dummy RSS feed content
        let dummy_feed = r#"
            <?xml version="1.0" encoding="UTF-8"?>
            <rss version="2.0">
                <channel>
                    <title>Test Podcast</title>
                    <link>http://example.com/feed</link>
                    <description>Test Description</description>
                    <image>
                        <url>http://example.com/image.jpg</url>
                    </image>
                </channel>
            </rss>
        "#
        .to_string();

        let fetcher = FakeFetcher { response: dummy_feed };

        let url = PodcastURL::new("http://example.com/feed");
        let podcast = download_and_create_podcast(&url, &fetcher).await.unwrap();

        assert_eq!(podcast.title(), "Test Podcast");
        assert_eq!(podcast.url().as_str(), url.as_str());
        assert_eq!(podcast.description(), Some("Test Description"));
        assert_eq!(podcast.website_url(), Some(url.as_str()));
    }

    #[tokio::test]
    async fn test_real_feed_download() {
        let fetcher = HttpFeedFetcher::new();
        let url = PodcastURL::new("https://feeds.zencastr.com/f/oSn1i316.rss");

        let podcast = download_and_create_podcast(&url, &fetcher).await.unwrap();

        println!("Downloaded podcast: {:#?}", podcast);

        // Basic sanity checks
        assert_eq!(podcast.title(), "Developer Voices");
        assert_eq!(podcast.url(), &url);
        assert!(podcast.description().is_some());
        assert!(podcast.image_url().is_some());
        assert_eq!(podcast.website_url(), Some("http://www.developervoices.com"));
    }

    // SAD PATHS

    #[tokio::test]
    async fn test_malformed_feed() {
        let malformed_xml = r#"<?xml version="1.0"?><rss><channel>"#;
        let fetcher = FakeFetcher { response: malformed_xml.to_string() };

        let result =
            download_and_create_podcast(&PodcastURL::new("http://example.com"), &fetcher).await;
        assert!(matches!(result, Err(DownloaderError::RssError(_))));
    }
}

// ====================
// File: ./src/podcast_factory.rs
// ====================
// src/podcast_factory.rs
use crate::errors::DownloaderError;
use crate::podcast::{Episode, EpisodeID, Podcast, PodcastURL};
use anyhow::Result;
use chrono::{DateTime, Utc};
use rss::Channel;

#[derive(Debug)]
pub struct ParsedFeed {
    pub channel: Channel,
}

#[derive(Debug, Clone, Copy)]
pub enum EpisodeSortOrder {
    NewestFirst,
    OldestFirst,
}

pub struct PodcastFactory {
    episode_limit: Option<usize>,
    sort_order: EpisodeSortOrder,
}

impl Default for PodcastFactory {
    fn default() -> Self {
        Self { episode_limit: None, sort_order: EpisodeSortOrder::NewestFirst }
    }
}

impl PodcastFactory {
    pub fn new() -> Self {
        Self::default()
    }

    // Builder methods
    pub fn with_episode_limit(mut self, limit: usize) -> Self {
        self.episode_limit = Some(limit);
        self
    }

    pub fn with_sort_order(mut self, order: EpisodeSortOrder) -> Self {
        self.sort_order = order;
        self
    }

    pub fn create_podcast(
        &self,
        parsed: ParsedFeed,
        feed_url: String,
    ) -> Result<Podcast, DownloaderError> {
        let mut episodes: Vec<Episode> = parsed
            .channel
            .items()
            .iter()
            .filter_map(|item| {
                let id = item
                    .guid()
                    .map(|g| g.value().to_string())
                    .or_else(|| item.link().map(String::from))?;
                let title = item.title()?.to_string();
                let description = item.description().map(String::from);
                let enclosure = item.enclosure()?; // enclosure is Option<rss::Enclosure>
                let audio_url = enclosure.url().to_string();
                let size_in_bytes = enclosure.length().parse::<u64>().ok();
                let duration = item.itunes_ext().and_then(|it| it.duration().map(String::from));
                let pub_date = item
                    .pub_date()
                    .and_then(|s| DateTime::parse_from_rfc2822(s).ok())
                    .map(|dt| dt.with_timezone(&Utc))
                    .unwrap_or_else(Utc::now);

                Some(Episode::new(
                    EpisodeID::new(&id),
                    title,
                    description,
                    pub_date,
                    duration,
                    audio_url,
                    size_in_bytes,
                ))
            })
            .collect();

        if let Some(limit) = self.episode_limit {
            episodes.truncate(limit);
        }

        if let EpisodeSortOrder::OldestFirst = self.sort_order {
            episodes.reverse();
        }

        Ok(Podcast::new(
            PodcastURL::new(&feed_url),
            parsed.channel.title().to_string(),
            Some(parsed.channel.description().to_string()),
            parsed.channel.image().map(|img| img.url().to_string()),
            Some(parsed.channel.link().to_string()),
            episodes,
        ))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use rss::{ChannelBuilder, ImageBuilder};

    #[test]
    fn test_create_podcast_from_parsed_feed() {
        // Create a minimal RSS Channel for testing
        let factory = PodcastFactory::new()
            .with_episode_limit(10)
            .with_sort_order(EpisodeSortOrder::NewestFirst);

        let image = ImageBuilder::default().url("http://example.com/image.jpg".to_string()).build();

        let url = "http://example.com/feed".to_string();
        let channel = ChannelBuilder::default()
            .title("Test Podcast".to_string())
            .link(url.to_string())
            .description("Test Description".to_string())
            .image(image)
            .build();

        let parsed = ParsedFeed { channel };
        let podcast = factory.create_podcast(parsed, url).unwrap();

        // Verify the basic fields are correctly mapped
        assert_eq!(podcast.title(), "Test Podcast");
        assert_eq!(podcast.url(), &PodcastURL::new("http://example.com/feed"));
        assert_eq!(podcast.description(), Some("Test Description"));
        assert_eq!(podcast.image_url(), Some("http://example.com/image.jpg"));
        assert_eq!(podcast.website_url(), Some("http://example.com/feed"));
        assert!(podcast.episodes().is_empty());
    }
}

// ====================
// File: ./src/errors.rs
// ====================
// src/errors.rs
use thiserror::Error;

#[derive(Error, Debug)]
pub enum PodcastError {
    #[error("Feed parsing error: {0}")]
    ParseError(String),

    #[error("Missing required field: {0}")]
    MissingField(String),

    #[error("Invalid feed URL: {0}")]
    InvalidUrl(String),

    #[error("Feed too large: {size} bytes")]
    FeedTooLarge { size: usize },

    #[error("Failed to save podcast url: {0}")]
    SaveFailed(String), // Store the URL as a string
}

#[derive(Error, Debug)]
pub enum DownloaderError {
    #[error("Network error: {0}")]
    NetworkError(#[from] reqwest::Error), // For fetcher.fetch if it uses reqwest directly
    #[error("RSS parsing error: {0}")]
    RssError(#[from] rss::Error), // For rss::Channel::read_from
    #[error("Download failed: {0}")]
    Failed(String),
}

#[derive(Error, Debug)]
pub enum PipelineError {
    #[error("Download operation failed: {0}")]
    DownloadFailed(#[from] DownloaderError),
    #[error("Save operation failed: {0}")]
    SaveFailedWithMessage(String),
    #[error("Save operation failed with underlying cause: {source}")]
    SaveFailedWithSource {
        message: String,
        #[source]
        source: Box<dyn std::error::Error + Send + Sync>,
    },
    #[error("URL evaluation failed: {0}")]
    EvaluationFailed(String),
    #[error("Evaluation the url failed with underlying cause: {source}")]
    EvaluationFailedWithSource {
        message: String,
        #[source]
        source: DownloaderError,
    },
    #[error("Pipeline is in an invalid state: {0}")]
    InvalidState(String), // e.g., Save called when no podcast in context
    #[error("An earlier step in the pipeline failed: {0}")] // {0} will display source
    UpstreamError(#[from] Box<PipelineError>),
}

// ====================
// File: ./src/main.rs
// ====================
// src/main.rs
use chrono::Utc;
use rustero::app::{self, App};
use rustero::commands::podcast_algebra::{CommandAccumulator, PipelineData, run_commands};
use rustero::commands::podcast_commands::PodcastCmd;
use rustero::commands::podcast_pipeline_interpreter::PodcastPipelineInterpreter;
use rustero::event::AppEvent;
use rustero::opml::opml_parser::OpmlFeedEntry;
use rustero::podcast::{Episode, EpisodeID, Podcast, PodcastURL};
use rustero::podcast_download::{FeedFetcher, HttpFeedFetcher};
use std::sync::Arc;
use tokio::sync::broadcast;
use tokio::sync::broadcast::{Receiver, Sender};

const SAMPLE_SHOW_NOTES_1: &str = r#"
<h1>Welcome to Episode 42: The Future of Rust</h1>

<p>In this episode, we talk with <strong>Jane Doe</strong>, a senior engineer at Rustaceans Inc., about what's coming next in the Rust ecosystem.</p>

<ul>
  <li>🦀 The impact of <a href="https://blog.rust-lang.org">Rust 2024 Edition</a></li>
  <li>📦 Tips for managing large crates</li>
  <li>🛠️ Async/Await best practices in real-world projects</li>
</ul>

<blockquote>
  “Rust lets us write safe, fast code — and helps us sleep better at night.” – Jane Doe
</blockquote>

<h2>Resources Mentioned</h2>
<ol>
  <li><a href="https://doc.rust-lang.org/book/">The Rust Book</a></li>
  <li><a href="https://tokio.rs">Tokio Async Runtime</a></li>
  <li><a href="https://serde.rs">Serde Serialization</a></li>
</ol>

<p>Be sure to <strong>subscribe</strong> and leave us a review on your favorite podcast app!</p>
"#;
const SAMPLE_SHOW_NOTES_2: &str = r#"
123456789012345678901234567890
223456789012345678901234567890
323456789012345678901234567890
423456789012345678901234567890
523456789012345678901234567890
623456789012345678901234567890
723456789012345678901234567890
823456789012345678901234567890
923456789012345678901234567890
102345678901234567890123456789
112345678901234567890123456789
122345678901234567890123456789
13v
142345678901234567890123456789
152345678901234567890123456789
16v
172345678901234567890123456789
182345678901234567890123456789
192345678901234567890123456789
202345678901234567890123456789
212345678901234567890123456789
222345678901234567890123456789
232345678901234567890123456789
"#;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // Channel for events
    let (event_tx, app_event_rx): (Sender<AppEvent>, Receiver<AppEvent>) =
        broadcast::channel::<AppEvent>(32);

    // Create a new app instance
    let mut app = App::new(app_event_rx);

    // let fetcher: Arc<dyn FeedFetcher + Send + Sync> = Arc::new(HttpFeedFetcher::new());
    // let mut interpreter = PodcastPipelineInterpreter::new(fetcher.clone(), event_tx.clone());
    // 
    // let cmd_seq1 = PodcastCmd::eval_url_from_str(
    //     "https://feeds.zencastr.com/f/oSn1i316.rss", // URL as string for EvalUrl
    //     PodcastCmd::download(
    //         // This URL is a fallback if EvalUrl somehow didn't populate the accumulator
    //         // or if the interpreter logic for Download was different.
    //         // With current interpreter, eval'd URL takes precedence.
    //         PodcastURL::new("http://unused-fallback.com/rss"),
    //         PodcastCmd::save(PodcastCmd::end()),
    //     ),
    // );
    // 
    // println!("--- Running Sequence 1: Eval -> Download -> Save ---");
    // let initial_acc: CommandAccumulator = Ok(PipelineData::default());
    // let result1 = run_commands(&cmd_seq1, initial_acc, &mut interpreter).await;
    // 
    // println!("{}", result1.is_err());

    // Create test episodes using the proper constructor
    let test_episodes_1 = vec![
        Episode::new(
            EpisodeID::new("ep1"),
            "First Episode".to_string(),
            Some(SAMPLE_SHOW_NOTES_2.to_string()),
            Utc::now(),
            Some("20:00".to_string()),
            "http://example.com/ep1.mp3".to_string(),
            Some(1024 * 1024), // 1MB size
        ),
        Episode::new(
            EpisodeID::new("ep2"),
            "Second Episode".to_string(),
            Some("This is episode 2".to_string()),
            Utc::now(),
            Some("25:00".to_string()),
            "http://example.com/ep2.mp3".to_string(),
            Some(1024 * 1024 * 2), // 2MB size
        ),
    ];

    let test_episodes_2 = vec![
        Episode::new(
            EpisodeID::new("ep10"),
            "10th Episode".to_string(),
            Some("This is episode 10".to_string()),
            Utc::now(),
            Some("20:00".to_string()),
            "http://example.com/ep10.mp3".to_string(),
            Some(1024 * 1024), // 1MB size
        ),
        Episode::new(
            EpisodeID::new("ep11"),
            "11th Episode".to_string(),
            Some("This is episode 11".to_string()),
            Utc::now(),
            Some("25:00".to_string()),
            "http://example.com/ep11.mp3".to_string(),
            Some(1024 * 1024 * 2), // 2MB size
        ),
    ];

    // Create a test podcast with episodes
    let test_podcast = Podcast::new(
        PodcastURL::new("http://example.com/feed1"),
        "Rust Daily News".to_string(),
        Some("Daily news about Rust".to_string()),
        None,
        None,
        test_episodes_1.clone(),
    );
    app.add_podcast(test_podcast);

    // Add another test podcast
    let test_podcast2 = Podcast::new(
        PodcastURL::new("http://example.com/feed2"),
        "Programming Tips".to_string(),
        Some("Programming tips and tricks".to_string()),
        None,
        None,
        test_episodes_2.clone(),
    );
    app.add_podcast(test_podcast2);

    let dummy_opml_entries = vec![
        OpmlFeedEntry {
            title: "Test Feed 1 (Syntax)".to_string(),
            xml_url: "http://feed.syntax.fm/rss".to_string(), // Known working feed for testing
            html_url: Some("https://syntax.fm".to_string()),
        },
        OpmlFeedEntry {
            title: "Test Feed 2 (Darknet Diaries)".to_string(),
            xml_url: "https://feeds.darknetdiaries.com/darknet-diaries.libsyn.com/rss".to_string(),
            html_url: None,
        },
        // Add a known failing one if you want to test error path (optional for this step)
        // OpmlFeedEntry {
        //     title: "Test Feed 3 (NonExistent)".to_string(),
        //     xml_url: "http://nonexistentfeed.example.com/rss".to_string(),
        //     html_url: None,
        // },
    ];

    let cmd_process_opml: PodcastCmd = PodcastCmd::process_opml_entries(dummy_opml_entries, PodcastCmd::end());
    let fetcher: Arc<dyn FeedFetcher + Send + Sync> = Arc::new(HttpFeedFetcher::new());

    let mut interpreter: PodcastPipelineInterpreter = PodcastPipelineInterpreter::new(fetcher.clone(), event_tx.clone());
    let initial_acc_for_opml: CommandAccumulator = Ok(PipelineData::default());

    println!("--- Running OPML Entry Processing Sequence ---");
    let opml_processing_result: CommandAccumulator =
        run_commands(&cmd_process_opml, initial_acc_for_opml, &mut interpreter).await;

    match opml_processing_result {
        Ok(_) => println!("OPML entry processing command finished."),
        Err(e) => eprintln!("OPML entry processing command failed: {:?}", e),
    }

    // match result1 {
    //     Ok(data) => {
    //         println!("\nSequence 1 completed successfully.");
    //         if let Some(p) = data.current_podcast {
    //             // current_podcast should still be Some after save
    //             println!("Last processed podcast in accumulator: {}", p);
    //         } else {
    //             println!(
    //                 "Sequence 1 completed, but no podcast was in the final accumulator context."
    //             );
    //         }
    //
    //         Ok(()) // Explicitly return Ok(()) for the success case of main
    //     }
    //     Err(pipeline_err) => {
    //         eprintln!("\nSequence 1 failed: {}", pipeline_err);
    //         Err(anyhow!(pipeline_err)) // Using anyhow! macro
    //     }
    // }
    //
    // Start the UI with our initialized app
    app::start_ui(Some(app))
}

// ====================
// File: ./src/commands/podcast_commands.rs
// ====================
// src/commands/podcast_commands.rs
use crate::opml::opml_parser::OpmlFeedEntry;
use crate::podcast::PodcastURL;

// This enum represents one "layer" of our command structure,
// including the 'next' command.
#[derive(Debug, Clone)]
pub enum PodcastCmd {
    EvalUrl(PodcastURL, Box<PodcastCmd>),
    Download(PodcastURL, Box<PodcastCmd>),
    Save(Box<PodcastCmd>),
    ProcessOpmlEntries(Vec<OpmlFeedEntry>, Box<PodcastCmd>),
    End,
}

impl PodcastCmd {
    pub fn eval_url(url: PodcastURL, next: PodcastCmd) -> Self {
        PodcastCmd::EvalUrl(url, Box::new(next))
    }

    // Helper to create EvalUrl from a string
    pub fn eval_url_from_str(url_str: &str, next: PodcastCmd) -> Self {
        PodcastCmd::EvalUrl(PodcastURL::new(url_str), Box::new(next))
    }

    pub fn download(url: PodcastURL, next: PodcastCmd) -> Self {
        PodcastCmd::Download(url, Box::new(next))
    }

    pub fn save(next: PodcastCmd) -> Self {
        PodcastCmd::Save(Box::new(next))
    }

    pub fn process_opml_entries(entries: Vec<OpmlFeedEntry>, next: PodcastCmd) -> Self {
        PodcastCmd::ProcessOpmlEntries(entries, Box::new(next))
    }

    pub fn end() -> Self {
        PodcastCmd::End
    }
}

// ====================
// File: ./src/commands/podcast_pipeline_interpreter.rs
// ====================
// src/commands/podcast_pipeline_interpreter.rs
use crate::commands::interpreter_helpers::{
    ValidationStepResult, try_validate_via_head, try_validate_via_partial_get,
    validate_url_syntax_and_scheme,
};
use crate::commands::podcast_algebra::{
    CommandAccumulator, PipelineData, PodcastAlgebra, run_commands,
};
use crate::commands::podcast_commands::PodcastCmd;
use crate::errors::PipelineError;
use crate::event::AppEvent;
use crate::opml::opml_parser::OpmlFeedEntry;
use crate::podcast::PodcastURL;
use crate::podcast_download::{FeedFetcher, download_and_create_podcast};
use async_trait::async_trait;
use std::sync::Arc;
use tokio::sync::broadcast;

pub struct PodcastPipelineInterpreter {
    fetcher: Arc<dyn FeedFetcher + Send + Sync>,
    event_tx: broadcast::Sender<AppEvent>,
}

impl PodcastPipelineInterpreter {
    pub fn new(
        fetcher: Arc<dyn FeedFetcher + Send + Sync>,
        event_tx: broadcast::Sender<AppEvent>,
    ) -> Self {
        Self { fetcher, event_tx }
    }
}

#[async_trait]
impl PodcastAlgebra for PodcastPipelineInterpreter {
    async fn interpret_eval_url(
        &mut self,
        url_to_eval: &PodcastURL,
        current_acc: CommandAccumulator,
    ) -> CommandAccumulator {
        let Ok(mut pipeline_data) = current_acc else {
            return current_acc;
        };
        let url_str = url_to_eval.as_str();
        println!("Interpreter: Evaluating URL: '{}'", url_str);

        if let Err(e) = validate_url_syntax_and_scheme(url_str).await {
            return Err(e);
        }

        // Call helper for HEAD validation
        match try_validate_via_head(self.fetcher.as_ref(), url_str).await {
            Ok(ValidationStepResult::Validated) => {
                pipeline_data.last_evaluated_url = Some(url_to_eval.clone());
                pipeline_data.current_podcast = None;
                return Ok(pipeline_data);
            }
            Ok(ValidationStepResult::Inconclusive) => {
                println!(
                    "Interpreter: HEAD validation inconclusive for {}. Proceeding to partial GET.",
                    url_str
                );
            }
            Err(head_downloader_error) => {
                println!(
                    "Interpreter: HEAD request for {} failed ({}). Proceeding to partial GET as fallback.",
                    url_str, head_downloader_error
                );
            }
        }

        match try_validate_via_partial_get(self.fetcher.as_ref(), url_str).await {
            Ok(ValidationStepResult::Validated) => {
                pipeline_data.last_evaluated_url = Some(url_to_eval.clone());
                pipeline_data.current_podcast = None;
                Ok(pipeline_data)
            }
            Ok(ValidationStepResult::Inconclusive) => {
                Err(PipelineError::EvaluationFailed(format!(
                    "URL content (first 4KB) of '{}' does not appear to be a valid RSS/Atom feed.",
                    url_str
                )))
            }
            Err(partial_get_downloader_error) => Err(PipelineError::EvaluationFailed(format!(
                "Failed to fetch partial content for URL evaluation of '{}': {}",
                url_str, partial_get_downloader_error
            ))),
        }
    }

    async fn interpret_download(
        &mut self,
        explicit_url_from_command: &PodcastURL,
        current_acc: CommandAccumulator,
    ) -> CommandAccumulator {
        let Ok(mut pipeline_data) = current_acc else {
            return current_acc;
        }; // Propagate error

        // Strategy: Use evaluated URL if available, otherwise use the one from the Download command.
        let url_to_use = match &pipeline_data.last_evaluated_url {
            Some(eval_url) => {
                println!("Interpreter: Using evaluated URL for download: {}", eval_url.as_str());
                eval_url
            }
            None => {
                println!(
                    "Interpreter: No evaluated URL in context, using URL from Download command: {}",
                    explicit_url_from_command.as_str()
                );
                explicit_url_from_command
            }
        };

        println!("Interpreter: Attempting download from: {}...", url_to_use.as_str());

        let podcast_obj = download_and_create_podcast(url_to_use, self.fetcher.as_ref()).await?; // The '?' handles the Result and early returns Err(DownloaderError) if needed

        println!("Interpreter: Successfully downloaded '{}'.", podcast_obj.title());
        pipeline_data.current_podcast = Some(podcast_obj);
        pipeline_data.last_evaluated_url = None; // "Consume" the evaluated URL
        Ok(pipeline_data)
    }

    async fn interpret_save(&mut self, current_acc: CommandAccumulator) -> CommandAccumulator {
        let Ok(data) = current_acc else {
            return current_acc;
        }; // Propagate error

        if let Some(podcast_to_save) = &data.current_podcast {
            println!(
                "Interpreter: Saving podcast (from accumulator): '{}'...",
                podcast_to_save.title()
            );

            // Step 1: Serialize (handle its potential error)
            let json_to_write = match serde_json::to_string_pretty(podcast_to_save) {
                Ok(s) => s,
                Err(serde_err) => {
                    return Err(PipelineError::SaveFailedWithSource {
                        // Use the same error variant
                        message: format!("Serialization failed for '{}'", podcast_to_save.title()),
                        source: Box::new(serde_err), // Box the serde_json::Error
                    });
                }
            };

            match std::fs::write("podcast.json", json_to_write).map_err(
                |io_error: std::io::Error| PipelineError::SaveFailedWithSource {
                    message: format!(
                        "Failed to write podcast '{}' to disk",
                        podcast_to_save.title()
                    ),
                    source: Box::new(io_error),
                },
            ) {
                Ok(_) => {
                    // fs::write succeeded
                    println!("Interpreter: Podcast '{}' saved.", podcast_to_save.title());
                    Ok(data) // Return the original PipelineData
                }
                Err(pipeline_error) => Err(pipeline_error), // fs::write failed, map_err converted it
            }
        } else {
            eprintln!("Interpreter: Save command executed, but no podcast in accumulator to save.");
            Err(PipelineError::InvalidState(
                "Save called without a podcast in accumulator".to_string(),
            ))
        }
    }

    async fn interpret_process_opml_entries(
        &mut self,
        feed_entries_to_process: &[OpmlFeedEntry],
        current_acc: CommandAccumulator,
    ) -> CommandAccumulator {
        // Propagate error if the accumulator for ProcessOpmlEntries itself is bad
        let Ok(data) = current_acc else {
            return current_acc;
        };

        if feed_entries_to_process.is_empty() {
            println!("Interpreter: No OPML feed entries to process.");
            return Ok(data); // Nothing to do, success for this step
        }

        println!(
            "Interpreter: Processing {} OPML feed entries sequentially...",
            feed_entries_to_process.len()
        );

        for entry in feed_entries_to_process.iter() {
            let podcast_url_from_opml: PodcastURL = PodcastURL::new(&entry.xml_url);
            let command_sequence_for_entry: PodcastCmd = PodcastCmd::eval_url(
                podcast_url_from_opml.clone(),
                PodcastCmd::download(
                    podcast_url_from_opml.clone(), // Fallback URL for download
                    PodcastCmd::save(PodcastCmd::end()),
                ),
            );

            let mut sub_interpreter: PodcastPipelineInterpreter =
                PodcastPipelineInterpreter::new(self.fetcher.clone(), self.event_tx.clone());
            let initial_sub_acc: CommandAccumulator = Ok(PipelineData::default());

            let sub_result: CommandAccumulator = run_commands(
                &command_sequence_for_entry,
                initial_sub_acc,
                &mut sub_interpreter,
            )
            .await;

            if sub_result.is_err() {
                eprintln!(
                    "[OPML Processor] Sub-pipeline for {} failed: {:?}",
                    entry.title,
                    sub_result.unwrap_err()
                );
            }
        }

        Ok(data)
    }

    async fn interpret_end(&mut self, final_acc: CommandAccumulator) -> CommandAccumulator {
        println!("Interpreter: Reached End. Final accumulator state: {:?}", final_acc);
        final_acc
    }
}

// ====================
// File: ./src/commands/mod.rs
// ====================
// src/commands/mod.rs
mod interpreter_helpers;
pub mod podcast_algebra;
pub mod podcast_commands;
pub mod podcast_pipeline_interpreter;

// ====================
// File: ./src/commands/podcast_algebra.rs
// ====================
// src/commands/podcast_cmd.rs (continued)
use crate::errors::PipelineError;
use crate::podcast::{Podcast, PodcastURL};

use crate::commands::podcast_commands::PodcastCmd;
use crate::opml::opml_parser::OpmlFeedEntry;
use async_trait::async_trait;

#[derive(Debug, Clone, Default)]
pub struct PipelineData {
    pub last_evaluated_url: Option<PodcastURL>, // Result from EvalUrl
    pub current_podcast: Option<Podcast>,       // Result from Download
}

// The Accumulator type that will be threaded through
pub type CommandAccumulator = Result<PipelineData, PipelineError>;

#[async_trait]
pub trait PodcastAlgebra {
    async fn interpret_eval_url(
        &mut self,
        url_to_eval: &PodcastURL,
        current_acc: CommandAccumulator,
    ) -> CommandAccumulator;

    async fn interpret_download(
        &mut self,
        // URL explicitly provided by the Download command node
        explicit_url_from_command: &PodcastURL,
        current_acc: CommandAccumulator,
    ) -> CommandAccumulator;

    async fn interpret_save(
        &mut self,
        // Save implicitly uses data from the accumulator
        current_acc: CommandAccumulator,
    ) -> CommandAccumulator;

    async fn interpret_process_opml_entries(
        &mut self,
        feed_entries_to_process: &[OpmlFeedEntry],
        current_acc: CommandAccumulator,
    ) -> CommandAccumulator;

    async fn interpret_end(&mut self, final_acc: CommandAccumulator) -> CommandAccumulator;
}
pub async fn run_commands(
    command: &PodcastCmd,
    initial_accumulator: CommandAccumulator,
    algebra: &mut impl PodcastAlgebra,
) -> CommandAccumulator {
    let mut current_acc = initial_accumulator;
    let mut current_cmd_node = command;

    loop {
        // Algebra methods are responsible for checking current_acc.is_err()
        // and propagating the error if they don't intend to handle/recover it.
        match current_cmd_node {
            PodcastCmd::EvalUrl(url, next_cmd) => {
                current_acc = algebra.interpret_eval_url(url, current_acc).await;
                current_cmd_node = next_cmd;
            }
            PodcastCmd::Download(url, next_cmd) => {
                current_acc = algebra.interpret_download(url, current_acc).await;
                current_cmd_node = next_cmd;
            }
            PodcastCmd::Save(next_cmd) => {
                current_acc = algebra.interpret_save(current_acc).await;
                current_cmd_node = next_cmd;
            }

            PodcastCmd::ProcessOpmlEntries(location, next_cmd) => {
                current_acc = algebra.interpret_process_opml_entries(&location, current_acc).await;
                current_cmd_node = next_cmd;
            }

            PodcastCmd::End => {
                current_acc = algebra.interpret_end(current_acc).await;
                break; // Exit the loop
            }
        }
    }
    current_acc
}

// ====================
// File: ./src/commands/interpreter_helpers.rs
// ====================
// src/commands/interpreter_helpers.rs
use crate::errors::{DownloaderError, PipelineError};
use crate::podcast_download::{FeedFetcher};

#[derive(Debug)]
pub(super) enum ValidationStepResult {
    Validated,
    Inconclusive,
}
// Define your helper functions there as pub(super) async fn or pub(crate) async fn
// (making them accessible within the commands module or the crate).
pub(super) async fn validate_url_syntax_and_scheme(
    url_str: &str,
) -> Result<reqwest::Url, PipelineError> {
    // Step 1: Basic URL parsing
    let parsed_url = reqwest::Url::parse(url_str).map_err(|parse_err| {
        PipelineError::EvaluationFailed(format!(
            "Invalid URL format for '{}': {}",
            url_str, parse_err
        ))
    })?;

    // Step 2: Check scheme (http/https)
    if parsed_url.scheme() != "http" && parsed_url.scheme() != "https" {
        return Err(PipelineError::EvaluationFailed(format!(
            "Invalid URL scheme for '{}': '{}'. Only http/https supported.",
            url_str,
            parsed_url.scheme()
        )));
    }
    Ok(parsed_url)
}

// Helper 3: Attempt to validate via HEAD request (Content-Type)
// Now takes `fetcher` as an argument
pub(super) async fn try_validate_via_head(
    // Changed to pub(super)
    fetcher: &(dyn FeedFetcher + Send + Sync), // Pass the fetcher trait object
    url_str: &str,
) -> Result<ValidationStepResult, DownloaderError> {
    match fetcher.fetch_headers(url_str).await {
        Ok(headers) => {
            if let Some(content_type) = headers.get("content-type") {
                let ct_lower = content_type.to_lowercase();
                if ct_lower.contains("application/rss+xml")
                    || ct_lower.contains("application/atom+xml")
                    || ct_lower.contains("application/xml")
                    || ct_lower.contains("text/xml")
                {
                    println!(
                        "Interpreter Helper (HEAD): URL validated by Content-Type: {}",
                        content_type
                    );
                    Ok(ValidationStepResult::Validated)
                } else {
                    println!(
                        "Interpreter Helper (HEAD): Content-Type '{}' inconclusive.",
                        content_type
                    );
                    Ok(ValidationStepResult::Inconclusive)
                }
            } else {
                println!("Interpreter Helper (HEAD): No Content-Type header found.");
                Ok(ValidationStepResult::Inconclusive)
            }
        }
        Err(e) => {
            println!("Interpreter Helper (HEAD): Request failed for {}: {}", url_str, e);
            Err(e)
        }
    }
}

// Helper 4: Attempt to validate via Partial GET (content sniffing)
// Fallback to partial GET request. This is the final validation attempt.
// The result of this match block will be the function's return value.
pub(super) async fn try_validate_via_partial_get(
    // Changed to pub(super)
    fetcher: &(dyn FeedFetcher + Send + Sync), // Pass the fetcher trait object
    url_str: &str,
) -> Result<ValidationStepResult, DownloaderError> {
    match fetcher.fetch_partial_content(url_str, (0, 4095)).await {
        Ok(partial_content) => {
            if partial_content.to_lowercase().contains("<rss")
                || partial_content.to_lowercase().contains("<feed")
            {
                println!("Interpreter Helper (Partial GET): URL validated by content inspection.");
                Ok(ValidationStepResult::Validated)
            } else {
                println!("Interpreter Helper (Partial GET): Content (first 4KB) inconclusive.");
                Ok(ValidationStepResult::Inconclusive)
            }
        }
        Err(e) => {
            println!("Interpreter Helper (Partial GET): Request failed for {}: {}", url_str, e);
            Err(e)
        }
    }
}

// ====================
// File: ./src/app.rs
// ====================
// src/app.rs
use crate::event::AppEvent;
use crate::podcast::{Episode, Podcast, PodcastURL};
use crate::ui::format_description;
use crate::widgets::scrollable_paragraph::ScrollableParagraphState;
use anyhow::Result;
use crossterm::{
    event::{self, DisableMouseCapture, EnableMouseCapture, Event, KeyCode},
    execute,
    terminal::{EnterAlternateScreen, LeaveAlternateScreen, disable_raw_mode, enable_raw_mode},
};
use ratatui::{Terminal, backend::Backend};
use std::io;
use tokio::sync::broadcast;
use tokio::sync::broadcast::Receiver;

#[derive(Debug, PartialEq, Eq, Clone, Copy)] // Added Clone, Copy for easier use
pub enum FocusedPanel {
    Podcasts,
    Episodes,
    ShowNotes,
    // Potentially Player in the future if it becomes interactive
}

impl Default for FocusedPanel {
    fn default() -> Self {
        FocusedPanel::Podcasts // Default focus to the podcasts panel
    }
}

pub struct App {
    pub should_quit: bool,
    pub podcasts: Vec<Podcast>,
    pub selected_podcast_index: Option<usize>,
    pub selected_episode_index: Option<usize>,
    pub playing_episode: Option<(String, String)>, // (podcast title, episode title)
    pub focused_panel: FocusedPanel,
    pub show_notes_state: ScrollableParagraphState,
    pub event_rx: Receiver<AppEvent>,
}

impl App {
    pub fn new(event_rx: Receiver<AppEvent>) -> App {
        let mut app = App {
            should_quit: false,
            podcasts: Vec::new(), // Initially empty, will be populated
            selected_podcast_index: None,
            selected_episode_index: None,
            playing_episode: None,
            focused_panel: FocusedPanel::default(), // Initialize focused panel
            show_notes_state: ScrollableParagraphState::default(),
            event_rx,
        };

        app.select_initial_items();

        app
    }

    // =================================== Update podcasts =========================================

    // Method to actually add a podcast into the App's state
    fn add_podcast_to_state(&mut self, podcast: Podcast) {
        let was_empty = self.podcasts.is_empty();
        self.podcasts.push(podcast);
        if was_empty {
            self.select_initial_items();
        }
    }

    // This is the crucial method that App will call in its loop to process incoming events.
    // It should be non-blocking if called frequently in the TUI loop.
    pub fn handle_pending_events(&mut self) {
        match self.event_rx.try_recv() {
            Ok(AppEvent::PodcastReadyForApp { podcast, timestamp: _ }) => {
                // Destructure directly
                println!("[APP] Received PodcastReadyForApp for: {}", podcast.title());
                self.add_podcast_to_state(podcast);
            }
            // Ok(other_event) => { /* For now, ignore other potential events if any */ }
            Err(broadcast::error::TryRecvError::Empty) => { /* No event, normal */ }
            Err(broadcast::error::TryRecvError::Lagged(n)) => {
                eprintln!("[APP] Event receiver lagged by {} messages!", n);
            }
            Err(broadcast::error::TryRecvError::Closed) => {
                println!("[APP] Event channel closed.");
                // self.should_quit = true; // Optionally quit if channel closes
            }
        }
    }

    // =================================== Update show notes =======================================

    // Method to update show notes content AND reset scroll
    // This should be called whenever the selected episode changes.
    fn update_show_notes_content(&mut self) {
        let new_content = if let Some(episode) = self.selected_episode() {
            format_description(episode.description())
        } else if self.selected_podcast().is_some() {
            "Select an episode to see its show notes.".to_string()
        } else {
            "Select a podcast and then an episode to see show notes.".to_string()
        };
        // CRITICAL: Update content after initial selection
        self.show_notes_state.set_content(new_content);
    }


    // ============================== Method to scroll show notes ==================================

    // Methods in App now modify show_notes_state directly
    // These are called by on_key when ShowNotes is focused
    pub fn scroll_show_notes_up_action(&mut self) {
        // Renamed to avoid conflict if methods added to state struct
        self.show_notes_state.scroll_up(1);
    }
    pub fn scroll_show_notes_down_action(&mut self) {
        // self.show_notes_state.calculate_max_scroll(show_notes_chunk_height)
        self.show_notes_state.scroll_down(1);
    }
    pub fn page_up_show_notes_action(&mut self) {
        self.show_notes_state.scroll_up(5); // Or a calculated page size
    }
    pub fn page_down_show_notes_action(&mut self) {
        self.show_notes_state.scroll_down(5); // Or a calculated page size
    }

    // Handle initial Podcast, Episode and Show Notes selection
    pub fn select_initial_items(&mut self) {
        if !self.podcasts.is_empty() {
            self.selected_podcast_index = Some(0); // Select the first podcast

            // Optionally, also select the first episode of that podcast
            if let Some(first_podcast) = self.podcasts.first() {
                if !first_podcast.episodes().is_empty() {
                    self.selected_episode_index = Some(0);
                } else {
                    self.selected_episode_index = None;
                }
            }
        } else {
            // No podcasts, so no selection
            self.selected_podcast_index = None;
            self.selected_episode_index = None;
        }
        // Set initial focus if not already default, already default, but could be explicit
        self.focused_panel = FocusedPanel::Podcasts;
        // CRITICAL: Update content after initial selection
        self.update_show_notes_content();
    }

    // Method to add a podcast (e.g., after download)
    // When adding the very first podcast, you want to select it.
    pub fn add_podcast(&mut self, podcast: Podcast) {
        let was_empty = self.podcasts.is_empty();
        self.podcasts.push(podcast);
        if was_empty {
            // Reselect, which will pick the new first one
            self.select_initial_items(); // This will call update_show_notes_content
        }
    }

    // --- Navigation methods for focused panel ---
    pub fn focus_next_panel(&mut self) {
        self.focused_panel = match self.focused_panel {
            FocusedPanel::Podcasts => FocusedPanel::Episodes,
            FocusedPanel::Episodes => FocusedPanel::ShowNotes,
            FocusedPanel::ShowNotes => FocusedPanel::Podcasts, // Cycle back
        };
        // If focus changed *to* ShowNotes or *from* ShowNotes, its content might not need to change
        // unless the selected episode also changed. Content is primarily tied to episode selection.
        // Scroll position of ShowNotes might be preserved or reset based on UX preference.
        // For now, scroll is preserved unless episode changes.
    }

    pub fn focus_prev_panel(&mut self) {
        self.focused_panel = match self.focused_panel {
            FocusedPanel::Podcasts => FocusedPanel::ShowNotes, // Cycle back
            FocusedPanel::Episodes => FocusedPanel::Podcasts,
            FocusedPanel::ShowNotes => FocusedPanel::Episodes,
        };
        // Similar logic for scroll as focus_next_panel
    }

    // ============================= Scrolling within the focused panel list =======================
    // =================================== Scrolling PODCASTs ======================================
    pub fn select_next_podcast(&mut self) {
        if self.podcasts.is_empty() {
            self.selected_podcast_index = None; // Clear selection if empty
            self.selected_episode_index = None;
            // CRITICAL: Update content after initial selection
            self.update_show_notes_content(); // Update show notes (will show placeholder)
            return;
        }
        let new_index = self.selected_podcast_index.map_or(0, |i| (i + 1) % self.podcasts.len());
        self.selected_podcast_index = Some(new_index);
        self.selected_episode_index = None; // Reset episode selection for new podcast

        // Auto-select first episode of the newly selected podcast
        if let Some(podcast) = self.selected_podcast() {
            if !podcast.episodes().is_empty() {
                self.selected_episode_index = Some(0);
            }
        }
        self.update_show_notes_content(); // Update content and reset scroll for new podcast/episode
    }

    pub fn select_prev_podcast(&mut self) {
        if self.podcasts.is_empty() {
            self.selected_podcast_index = None;
            self.selected_episode_index = None;
            self.update_show_notes_content();
            return;
        }
        let len = self.podcasts.len();
        let new_index = self.selected_podcast_index.map_or(len - 1, |i| (i + len - 1) % len);
        self.selected_podcast_index = Some(new_index);
        self.selected_episode_index = None;

        if let Some(podcast) = self.selected_podcast() {
            if !podcast.episodes().is_empty() {
                self.selected_episode_index = Some(0);
            }
        }
        self.update_show_notes_content();
    }

    // ==================================== Scrolling EPISODEs =====================================
    pub fn select_next_episode(&mut self) {
        if let Some(podcast) = self.selected_podcast() {
            let episodes = podcast.episodes();
            if episodes.is_empty() {
                self.selected_episode_index = None;
                self.update_show_notes_content(); // Update to "no episodes" message
                return;
            }
            let new_index = self.selected_episode_index.map_or(0, |i| (i + 1) % episodes.len());
            self.selected_episode_index = Some(new_index);
            self.update_show_notes_content(); // Update content and reset scroll for new episode
        } else {
            // No podcast selected, ensure episode index is None
            if self.selected_episode_index.is_some() {
                self.selected_episode_index = None;
                self.update_show_notes_content();
            }
        }
    }

    pub fn select_prev_episode(&mut self) {
        if let Some(podcast) = self.selected_podcast() {
            let episodes = podcast.episodes();
            if episodes.is_empty() {
                self.selected_episode_index = None;
                self.update_show_notes_content();
                return;
            }
            let len = episodes.len();
            let new_index = self.selected_episode_index.map_or(len - 1, |i| (i + len - 1) % len);
            self.selected_episode_index = Some(new_index);
            self.update_show_notes_content();
        } else {
            if self.selected_episode_index.is_some() {
                self.selected_episode_index = None;
                self.update_show_notes_content();
            }
        }
    }

    pub fn select_next_item_in_focused_list(&mut self) {
        match self.focused_panel {
            FocusedPanel::Podcasts => self.select_next_podcast(),
            FocusedPanel::Episodes => self.select_next_episode(),
            FocusedPanel::ShowNotes => {}
        }
    }

    pub fn select_prev_item_in_focused_list(&mut self) {
        match self.focused_panel {
            FocusedPanel::Podcasts => self.select_prev_podcast(),
            FocusedPanel::Episodes => self.select_prev_episode(),
            FocusedPanel::ShowNotes => { /* ... */ }
        }
    }

    // --- Key Handler ---
    pub fn on_key(&mut self, key: KeyCode) {
        // Handle global quit first
        if key == KeyCode::Char('q') {
            self.should_quit = true;
            return;
        }

        match self.focused_panel {
            FocusedPanel::Podcasts => match key {
                KeyCode::Down => self.select_next_podcast(),
                KeyCode::Up => self.select_prev_podcast(),
                KeyCode::Right | KeyCode::Tab => self.focus_next_panel(),
                KeyCode::Left | KeyCode::BackTab => self.focus_prev_panel(),
                _ => {}
            },
            FocusedPanel::Episodes => match key {
                KeyCode::Down => self.select_next_episode(),
                KeyCode::Up => self.select_prev_episode(),
                KeyCode::Right | KeyCode::Tab => self.focus_next_panel(),
                KeyCode::Left | KeyCode::BackTab => self.focus_prev_panel(),
                // KeyCode::Char(' ') => { /* Play/Pause logic */ }
                _ => {}
            },
            FocusedPanel::ShowNotes => match key {
                KeyCode::Down => self.scroll_show_notes_down_action(),
                KeyCode::Up => self.scroll_show_notes_up_action(),
                KeyCode::PageDown => self.page_down_show_notes_action(),
                KeyCode::PageUp => self.page_up_show_notes_action(),
                KeyCode::Right | KeyCode::Tab => self.focus_next_panel(),
                KeyCode::Left | KeyCode::BackTab => self.focus_prev_panel(),
                _ => {}
            },
        }
    }

    // --- Getters for selected items (no changes needed here from before) ---
    pub fn selected_podcast(&self) -> Option<&Podcast> {
        self.selected_podcast_index.and_then(|i| self.podcasts.get(i))
    }

    pub fn selected_episode(&self) -> Option<&Episode> {
        self.selected_podcast()
            .and_then(|p| self.selected_episode_index.and_then(|i| p.episodes().get(i)))
    }

    pub fn load_test_podcast(&mut self) {
        // Create a test podcast with some episodes
        let test_podcast = Podcast::new(
            PodcastURL::new("http://example.com/feed"),
            "Test Podcast".to_string(),
            Some("A test podcast".to_string()),
            None,
            None,
            vec![], // We can add test episodes here if needed
        );
        self.podcasts.push(test_podcast);
    }
}

pub fn start_ui(initial_app: Option<App>) -> Result<()> {
    // Set up the terminal
    enable_raw_mode()?;
    let mut stdout = io::stdout();
    execute!(stdout, EnterAlternateScreen, EnableMouseCapture)?;
    let backend = ratatui::backend::CrosstermBackend::new(stdout);
    let mut terminal = Terminal::new(backend)?;

    // Use provided app or create a new empty one
    let mut app = initial_app.unwrap_or_else(App::new);

    let res = run_app_loop(&mut terminal, &mut app);

    // Restore the terminal
    disable_raw_mode()?;
    execute!(terminal.backend_mut(), LeaveAlternateScreen, DisableMouseCapture)?;
    terminal.show_cursor()?;

    if let Err(e) = res {
        eprintln!("Error: {}", e);
    }

    Ok(())
}

pub fn run_app_loop<B: Backend>(terminal: &mut Terminal<B>, app: &mut App) -> Result<()> {
    while !app.should_quit {
        let frame_size = terminal.get_frame().size(); // Fetch once before drawing
        crate::ui::prepare_ui_layout(app, frame_size);
        terminal.draw(|f| crate::ui::ui::<B>(f, app))?;

        if event::poll(std::time::Duration::from_millis(100))? {
            // Poll with timeout
            if let Event::Key(key_event) = event::read()? {
                // key_event not just key
                app.on_key(key_event.code);
            }
        }

        // Add a small sleep here if your app does no other async work in this loop,
        // to yield CPU. If other async tasks are spawned, Tokio handles yielding.
        std::thread::sleep(std::time::Duration::from_millis(10)); // Example, if purely sync loop
    }

    Ok(())
}

// ====================
// File: ./src/widgets/mod.rs
// ====================
// src/widgets/mod.rs
pub(crate) mod scrollable_paragraph;

// ====================
// File: ./src/widgets/scrollable_paragraph.rs
// ====================
// src/widgets/scrollable_paragraph.rs
use unicode_width::UnicodeWidthChar;

#[derive(Debug, Default, Clone)]
pub struct ScrollableParagraphState {
    pub content: String, // Or ratatui::text::Text<'a> for styled text
    pub scroll_offset_vertical: u16,
    pub scroll_offset_horizontal: u16, // If you want horizontal scrolling too
    // You might also store:
    // - total_content_lines: usize (if you can calculate/estimate it)
    // - panel_height: u16 (from the layout, to cap scrolling)
    pub panel_height: u16, // <-- new
    pub panel_width: u16,  // Add this for wrap-aware calculations
}

impl ScrollableParagraphState {
    pub fn new(content: String) -> Self {
        Self {
            content,
            scroll_offset_vertical: 0,
            scroll_offset_horizontal: 0,
            panel_height: 0,
            panel_width: 0,
        }
    }
    fn calculate_content_height_lines(&self) -> u16 {
        // You are calculating calculate_content_height_lines() on the fly whenever max_scroll_vertical()
        // (and thus scroll_down()) is called, and also when set_dimensions() calls max_scroll_vertical().
        // This is fine, just potentially less performant if content is huge and these are called frequently,
        // but for typical show notes, it might be acceptable.
        let available_width = self.panel_width.saturating_sub(self.scroll_offset_horizontal);

        if available_width == 0 {
            return 0; // No space to render anything
        }
        let available_width_usize = available_width as usize;

        let total_rendered_lines = self.content.lines().fold(0u16, |acc, original_line| {
            let line_unicode_width: usize =
                original_line.chars().map(|c| UnicodeWidthChar::width(c).unwrap_or(0)).sum();

            let rendered_rows_for_this_line = if line_unicode_width == 0 {
                1 // An empty original line still takes up one rendered line
            } else {
                // Ceiling division: (numerator + denominator - 1) / denominator
                // How many groups of `denominator` fit into `numerator`, rounding UP:
                ((line_unicode_width + available_width_usize - 1) / available_width_usize) as u16
            };
            // eprintln!("Line: '{}', unicode_width: {}, panel_w: {}, rows: {}", original_line, line_unicode_width, self.panel_width, rendered_rows_for_this_line);
            acc.saturating_add(rendered_rows_for_this_line)
        });

        total_rendered_lines
    }

    pub fn max_scroll_vertical(&self) -> u16 {
        let total_content_height = self.calculate_content_height_lines();
        total_content_height.saturating_sub(self.panel_height)
    }
    pub fn set_content(&mut self, content: String) {
        // eprintln!("--- ScrollableParagraphState::set_content ---");
        // eprintln!("Received content (first 200 chars): {:.200}", content);
        // eprintln!("Content total original lines: {}", content.lines().count());

        self.content = content.trim().to_string();
        self.scroll_offset_vertical = 0; // Reset scroll when content changes
        self.scroll_offset_horizontal = 0;
    }

    // You'll also need a method to set the panel_width and panel_height.
    // This should be called from ui.rs whenever the layout chunk size for show notes is known.
    pub fn set_dimensions(&mut self, width: u16, height: u16) {
        let mut needs_scroll_recalc = false;
        if self.panel_width != width {
            self.panel_width = width;
            needs_scroll_recalc = true;
        }
        if self.panel_height != height {
            self.panel_height = height;
            needs_scroll_recalc = true; // Height change also affects max_scroll
        }

        if needs_scroll_recalc {
            // If dimensions change, the current scroll_offset_vertical might be invalid.
            // It should be clamped against the new max_scroll.
            let max_s = self.max_scroll_vertical();
            self.scroll_offset_vertical = self.scroll_offset_vertical.min(max_s);
        }
    }
    pub fn scroll_up(&mut self, amount: u16) {
        self.scroll_offset_vertical = self.scroll_offset_vertical.saturating_sub(amount);
    }

    pub fn scroll_down(&mut self, amount: u16) {
        let max_scroll = self.max_scroll_vertical();
        self.scroll_offset_vertical =
            self.scroll_offset_vertical.saturating_add(amount).min(max_scroll);
    }
}

